{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "# load dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Here the data is converte to numpy array aftering reading the file\n",
    "dataset = pd.read_csv(\"breastcancer.csv\")\n",
    "dataset.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 907us/step - loss: 22.9581 - acc: 0.3842\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.5229 - acc: 0.6305\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 907us/step - loss: 6.0484 - acc: 0.7302\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 5.1215 - acc: 0.6246\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 906us/step - loss: 4.6015 - acc: 0.6979\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 816us/step - loss: 4.3040 - acc: 0.7097\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 907us/step - loss: 3.9782 - acc: 0.7067\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 906us/step - loss: 3.7056 - acc: 0.7009\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.4535 - acc: 0.7449\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.3242 - acc: 0.7155\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.0526 - acc: 0.7683\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.8924 - acc: 0.7419\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6973 - acc: 0.7742\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4917 - acc: 0.7507\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.3959 - acc: 0.8240\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.1748 - acc: 0.7683\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 2.0363 - acc: 0.8270\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 816us/step - loss: 1.9096 - acc: 0.7977\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 1.7402 - acc: 0.8299\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6493 - acc: 0.8387\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.5714 - acc: 0.8446\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.4643 - acc: 0.8152\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.3826 - acc: 0.8680\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2580 - acc: 0.8446\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 998us/step - loss: 1.2037 - acc: 0.8710\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 1.1132 - acc: 0.8680\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 854us/step - loss: 1.0333 - acc: 0.8680\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.9976 - acc: 0.8827\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.9130 - acc: 0.8856\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.8824 - acc: 0.9062\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.8415 - acc: 0.8739\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 998us/step - loss: 0.7711 - acc: 0.9032\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 907us/step - loss: 0.7412 - acc: 0.9062\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6982 - acc: 0.9062\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6854 - acc: 0.9179\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6824 - acc: 0.8739\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6003 - acc: 0.9062\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.5612 - acc: 0.9091\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5387 - acc: 0.9032\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5400 - acc: 0.9003\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.4859 - acc: 0.9150\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 865us/step - loss: 0.4733 - acc: 0.9062\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4864 - acc: 0.9062\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 998us/step - loss: 0.4568 - acc: 0.9062\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 907us/step - loss: 0.4675 - acc: 0.9032\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.4855 - acc: 0.9003\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.4464 - acc: 0.9062\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4288 - acc: 0.9120\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.4745 - acc: 0.9032\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 907us/step - loss: 0.4625 - acc: 0.8974\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.4705 - acc: 0.9032\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.4654 - acc: 0.8974\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.4180 - acc: 0.9062\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.4135 - acc: 0.9032\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4296 - acc: 0.9003\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 907us/step - loss: 0.4872 - acc: 0.8886\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 907us/step - loss: 0.4755 - acc: 0.9062\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4272 - acc: 0.9003\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.3629 - acc: 0.9120\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.3833 - acc: 0.9150\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4118 - acc: 0.8974\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4034 - acc: 0.9120\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.3907 - acc: 0.9267\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 906us/step - loss: 0.3431 - acc: 0.9091\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 816us/step - loss: 0.3593 - acc: 0.8944\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 907us/step - loss: 0.3665 - acc: 0.9120\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.3485 - acc: 0.9003\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.3344 - acc: 0.9120\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3333 - acc: 0.9091\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3233 - acc: 0.9091\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3719 - acc: 0.9062\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3480 - acc: 0.9003\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 907us/step - loss: 0.3322 - acc: 0.9091\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.3030 - acc: 0.9120\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.3599 - acc: 0.9032\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3221 - acc: 0.8974\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2822 - acc: 0.9179\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3954 - acc: 0.875 - 0s 1ms/step - loss: 0.3091 - acc: 0.9179\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3099 - acc: 0.9091\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2838 - acc: 0.9032\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2681 - acc: 0.9150\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2805 - acc: 0.9208\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3112 - acc: 0.9238\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3596 - acc: 0.9091\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2576 - acc: 0.9150\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 816us/step - loss: 0.2641 - acc: 0.9091\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 816us/step - loss: 0.2775 - acc: 0.9032\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2609 - acc: 0.9179\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2571 - acc: 0.9091\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.2713 - acc: 0.9208\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3135 - acc: 0.9120\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3368 - acc: 0.8886\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2612 - acc: 0.9267\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2325 - acc: 0.9150\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2332 - acc: 0.9120\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 907us/step - loss: 0.2170 - acc: 0.9150\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.2123 - acc: 0.9179\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 907us/step - loss: 0.2762 - acc: 0.9150\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.2912 - acc: 0.9179\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.2504 - acc: 0.9208\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 20)                600       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "8/8 [==============================] - 0s 748us/step - loss: 0.1799 - acc: 0.9474\n",
      "[0.1798962652683258, 0.9473684430122375]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X=dataset.iloc[:,2:31].values\n",
    "Y=dataset.iloc[:,1].values\n",
    "labelencoder_Y = preprocessing.LabelEncoder()\n",
    "Y= labelencoder_Y.fit_transform(Y)\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X,Y,test_size=0.4, random_state=0)\n",
    "my_first_nn1 = Sequential() # create model\n",
    "my_first_nn1.add(Dense(20, input_dim=29, activation='relu')) # hidden layer\n",
    "my_first_nn1.add(Dense(1, activation='sigmoid')) # output layer\n",
    "my_first_nn1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "my_first_nn_fitted1 = my_first_nn1.fit(X_train1, Y_train1, epochs=100,initial_epoch=0)\n",
    "print(my_first_nn1.summary())\n",
    "print(my_first_nn1.evaluate(X_test1, Y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 37.9745 - acc: 0.6217\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.5150 - acc: 0.4956\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.9862 - acc: 0.3900\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 1.6011 - acc: 0.4985\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.9375 - acc: 0.5455\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 996us/step - loss: 0.7815 - acc: 0.5543\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.6192 - acc: 0.6657\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5335 - acc: 0.7390\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4730 - acc: 0.7654\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4215 - acc: 0.8270\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3753 - acc: 0.8446\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3496 - acc: 0.8680\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3347 - acc: 0.8651\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3119 - acc: 0.8827\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3311 - acc: 0.8592\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3103 - acc: 0.8710\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2870 - acc: 0.9003\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2750 - acc: 0.9091\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2883 - acc: 0.8886\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2887 - acc: 0.8856\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2757 - acc: 0.9062\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2635 - acc: 0.9003\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2512 - acc: 0.9091\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2468 - acc: 0.8974\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2384 - acc: 0.9120\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2381 - acc: 0.9091\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2383 - acc: 0.9120\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2337 - acc: 0.9032\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2299 - acc: 0.9120\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2467 - acc: 0.8974\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2283 - acc: 0.9032\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2480 - acc: 0.9091\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2249 - acc: 0.9120\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2350 - acc: 0.9003\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2189 - acc: 0.9150\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2239 - acc: 0.8915\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2230 - acc: 0.9062\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2099 - acc: 0.9208\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2530 - acc: 0.8915\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2542 - acc: 0.8974\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2875 - acc: 0.8915\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3047 - acc: 0.8827\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2321 - acc: 0.9208\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2176 - acc: 0.9062\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2092 - acc: 0.9150\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1823 - acc: 0.906 - 0s 1ms/step - loss: 0.2150 - acc: 0.9091\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2059 - acc: 0.9179\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2122 - acc: 0.9120\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2264 - acc: 0.8944\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2075 - acc: 0.9091\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2257 - acc: 0.9120\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2151 - acc: 0.9091\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2228 - acc: 0.8886\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2093 - acc: 0.9150\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2265 - acc: 0.9091\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2153 - acc: 0.9120\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2128 - acc: 0.9150\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2130 - acc: 0.9120\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2021 - acc: 0.9150\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2283 - acc: 0.9179\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2101 - acc: 0.9150\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1978 - acc: 0.9120\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2046 - acc: 0.9120\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2158 - acc: 0.9032\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2316 - acc: 0.9120\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2329 - acc: 0.9179\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2132 - acc: 0.9091\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2199 - acc: 0.9179\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2069 - acc: 0.9150\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2116 - acc: 0.9120\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2242 - acc: 0.9208\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1961 - acc: 0.9150\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2017 - acc: 0.9062\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2195 - acc: 0.9208\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2473 - acc: 0.8915\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1984 - acc: 0.9091\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2136 - acc: 0.9120\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2046 - acc: 0.9091\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1955 - acc: 0.9208\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2537 - acc: 0.9003\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2522 - acc: 0.8944\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2126 - acc: 0.9062\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1917 - acc: 0.9120\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2197 - acc: 0.9091\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2375 - acc: 0.9120\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2107 - acc: 0.9032\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2080 - acc: 0.9150\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2134 - acc: 0.9150\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 969us/step - loss: 0.1918 - acc: 0.9179\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 907us/step - loss: 0.2015 - acc: 0.9091\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 906us/step - loss: 0.1953 - acc: 0.9150\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2215 - acc: 0.9003\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 998us/step - loss: 0.1977 - acc: 0.9150\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.2021 - acc: 0.9062\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1901 - acc: 0.9062\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 907us/step - loss: 0.2064 - acc: 0.9032\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.1945 - acc: 0.9238\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2181 - acc: 0.9267\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 907us/step - loss: 0.2180 - acc: 0.9150\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 801us/step - loss: 0.2144 - acc: 0.9091\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 20)                600       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,461\n",
      "Trainable params: 1,461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "8/8 [==============================] - 0s 872us/step - loss: 0.1442 - acc: 0.9561\n",
      "[0.14417070150375366, 0.9561403393745422]\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X,Y,test_size=0.4, random_state=0)\n",
    "my_first_nn1 = Sequential() # create model\n",
    "my_first_nn1.add(Dense(20, input_dim=29, activation='relu')) # hidden layer\n",
    "my_first_nn1.add(Dense(20, input_dim=29, activation='relu')) # hidden layer\n",
    "my_first_nn1.add(Dense(20, input_dim=29, activation='relu')) # hidden layer\n",
    "my_first_nn1.add(Dense(1, activation='sigmoid')) # output layer\n",
    "my_first_nn1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "my_first_nn_fitted1 = my_first_nn1.fit(X_train1, Y_train1, epochs=100,initial_epoch=0)\n",
    "print(my_first_nn1.summary())\n",
    "print(my_first_nn1.evaluate(X_test1, Y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 20)                600       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "8/8 [==============================] - 0s 748us/step - loss: 0.0450 - acc: 0.9868\n",
      "[0.04502572491765022, 0.9868420958518982]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X,Y,test_size=0.4, random_state=0)\n",
    "my_first_nn1 = Sequential() # create model\n",
    "my_first_nn1.add(Dense(20, input_dim=29, activation='relu')) # hidden layer\n",
    "my_first_nn1.add(Dense(1, activation='sigmoid')) # output layer\n",
    "my_first_nn1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "X_train1 = sc.fit_transform(X_train1)\n",
    "X_test1 = sc.transform(X_test1)\n",
    "\n",
    "my_first_nn_fitted1 = my_first_nn1.fit(X_train1, Y_train1, epochs=100,verbose=0,initial_epoch=0)\n",
    "print(my_first_nn1.summary())\n",
    "print(my_first_nn1.evaluate(X_test1, Y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 20)                600       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,461\n",
      "Trainable params: 1,461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "8/8 [==============================] - 0s 748us/step - loss: 0.0453 - acc: 0.9825\n",
      "[0.04534636437892914, 0.9824561476707458]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X,Y,test_size=0.4, random_state=0)\n",
    "my_first_nn1 = Sequential() # create model\n",
    "my_first_nn1.add(Dense(20, input_dim=29, activation='relu')) # hidden layer\n",
    "my_first_nn1.add(Dense(20, input_dim=29, activation='relu')) # hidden layer\n",
    "my_first_nn1.add(Dense(20, input_dim=29, activation='relu')) # hidden layer\n",
    "my_first_nn1.add(Dense(1, activation='sigmoid')) # output layer\n",
    "my_first_nn1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "X_train1 = sc.fit_transform(X_train1)\n",
    "X_test1 = sc.transform(X_test1)\n",
    "\n",
    "my_first_nn_fitted1 = my_first_nn1.fit(X_train1, Y_train1, epochs=100,verbose=0,initial_epoch=0)\n",
    "print(my_first_nn1.summary())\n",
    "print(my_first_nn1.evaluate(X_test1, Y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
