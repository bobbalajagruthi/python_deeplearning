{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Basic packages for creating dataframes and loading dataset\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt #Package for visualization\n",
    "\n",
    "import re #importing package for Regular expression operations\n",
    "\n",
    "from sklearn.model_selection import train_test_split #Package for splitting the data\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder #Package for conversion of categorical to Numerical\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer #Tokenization\n",
    "from keras.preprocessing.sequence import pad_sequences #Add zeros or crop based on the length\n",
    "from keras.models import Sequential #Sequential Neural Network\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D #For layers in Neural Network\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Sentiment.csv') #Looading the dataset\n",
    "\n",
    "data = data[['text','sentiment']] # Keeping only the neccessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13866</th>\n",
       "      <td>RT @cappy_yarbrough: Love to see men who will ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13867</th>\n",
       "      <td>RT @georgehenryw: Who thought Huckabee exceede...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13868</th>\n",
       "      <td>RT @Lrihendry: #TedCruz As President, I will a...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13869</th>\n",
       "      <td>RT @JRehling: #GOPDebate Donald Trump says tha...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13870</th>\n",
       "      <td>RT @Lrihendry: #TedCruz headed into the Presid...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13871 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "0      RT @NancyLeeGrahn: How did everyone feel about...   Neutral\n",
       "1      RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "2      RT @TJMShow: No mention of Tamir Rice and the ...   Neutral\n",
       "3      RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
       "4      RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
       "...                                                  ...       ...\n",
       "13866  RT @cappy_yarbrough: Love to see men who will ...  Negative\n",
       "13867  RT @georgehenryw: Who thought Huckabee exceede...  Positive\n",
       "13868  RT @Lrihendry: #TedCruz As President, I will a...  Positive\n",
       "13869  RT @JRehling: #GOPDebate Donald Trump says tha...  Negative\n",
       "13870  RT @Lrihendry: #TedCruz headed into the Presid...  Positive\n",
       "\n",
       "[13871 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: x.lower()) #converting to lower case\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-Z0-9\\s]', '', x))) #only a-z,A-Z,0-9 would be remaining in the data, else special characters are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt', ' ') #Removing Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(X)\n",
    "\n",
    "embed_dim = 128\n",
    "lstm_out = 196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createmodel():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "    return model\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "integer_encoded = labelencoder.fit_transform(data['sentiment'])\n",
    "y = to_categorical(integer_encoded)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 - 28s - loss: 0.8270 - accuracy: 0.6464\n",
      "144/144 - 2s - loss: 0.7617 - accuracy: 0.6699\n",
      "0.7616634368896484\n",
      "0.6699432134628296\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model = createmodel() #Function call to Sequential Neural Network\n",
    "model.fit(X_train, Y_train, epochs = 1, batch_size=batch_size, verbose = 2) #verbose the higher, the more messages\n",
    "score,acc = model.evaluate(X_test,Y_test,verbose=2,batch_size=batch_size)\n",
    "print(score)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model and use the saved model to predict on new text data (ex, “A lot of good things are happening. We are respected again throughout the world, and that's a great thing.@realDonaldTrump”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sentimentAnalysis.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model= load_model('sentimentAnalysis.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 ... 2 0 2]\n",
      "0         Neutral\n",
      "1        Positive\n",
      "2         Neutral\n",
      "3        Positive\n",
      "4        Positive\n",
      "           ...   \n",
      "13866    Negative\n",
      "13867    Positive\n",
      "13868    Positive\n",
      "13869    Negative\n",
      "13870    Positive\n",
      "Name: sentiment, Length: 13871, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(integer_encoded)\n",
    "print(data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-37b176203d54>:4: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "1/1 - 0s\n",
      "0\n",
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "sentence = ['A lot of good things are happening. We are respected again throughout the world, and that is a great thing.@realDonaldTrump']\n",
    "sentence = tokenizer.texts_to_sequences(sentence)\n",
    "sentence = pad_sequences(sentence, maxlen=28, dtype='int32', value=0)\n",
    "sentiment = model.predict_classes(sentence,batch_size=1,verbose = 2)[0]\n",
    "print(sentiment)\n",
    "if sentiment == 0:\n",
    "  print(\"Neutral\")\n",
    "elif sentiment < 0:\n",
    "  print(\"Negative\")\n",
    "elif sentiment > 0:\n",
    "  print(\"Positive\")\n",
    "else:\n",
    "  print(\"Can not be determined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GridSearchCV on the source code provided in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 - 51s - loss: 0.8259 - accuracy: 0.6484\n",
      "186/186 - 2s - loss: 0.7488 - accuracy: 0.6799\n",
      "744/744 - 55s - loss: 0.8239 - accuracy: 0.6453\n",
      "186/186 - 2s - loss: 0.7832 - accuracy: 0.6563\n",
      "744/744 - 57s - loss: 0.8228 - accuracy: 0.6451\n",
      "186/186 - 2s - loss: 0.7541 - accuracy: 0.6848\n",
      "744/744 - 55s - loss: 0.8281 - accuracy: 0.6441\n",
      "186/186 - 3s - loss: 0.7414 - accuracy: 0.6841\n",
      "744/744 - 69s - loss: 0.8162 - accuracy: 0.6498\n",
      "186/186 - 4s - loss: 0.7988 - accuracy: 0.6642\n",
      "Epoch 1/2\n",
      "744/744 - 119s - loss: 0.8282 - accuracy: 0.6492\n",
      "Epoch 2/2\n",
      "744/744 - 127s - loss: 0.6810 - accuracy: 0.7119\n",
      "186/186 - 8s - loss: 0.7441 - accuracy: 0.6885\n",
      "Epoch 1/2\n",
      "744/744 - 118s - loss: 0.8217 - accuracy: 0.6478\n",
      "Epoch 2/2\n",
      "744/744 - 89s - loss: 0.6824 - accuracy: 0.7111\n",
      "186/186 - 6s - loss: 0.7461 - accuracy: 0.6783\n",
      "Epoch 1/2\n",
      "744/744 - 122s - loss: 0.8240 - accuracy: 0.6484\n",
      "Epoch 2/2\n",
      "744/744 - 125s - loss: 0.6737 - accuracy: 0.7176\n",
      "186/186 - 8s - loss: 0.7388 - accuracy: 0.6880\n",
      "Epoch 1/2\n",
      "744/744 - 123s - loss: 0.8251 - accuracy: 0.6480\n",
      "Epoch 2/2\n",
      "744/744 - 91s - loss: 0.6742 - accuracy: 0.7130\n",
      "186/186 - 4s - loss: 0.7607 - accuracy: 0.6744\n",
      "Epoch 1/2\n",
      "744/744 - 66s - loss: 0.8220 - accuracy: 0.6460\n",
      "Epoch 2/2\n",
      "744/744 - 66s - loss: 0.6723 - accuracy: 0.7189\n",
      "186/186 - 5s - loss: 0.7884 - accuracy: 0.6744\n",
      "372/372 - 35s - loss: 0.8307 - accuracy: 0.6462\n",
      "93/93 - 2s - loss: 0.7583 - accuracy: 0.6633\n",
      "372/372 - 44s - loss: 0.8236 - accuracy: 0.6438\n",
      "93/93 - 3s - loss: 0.7542 - accuracy: 0.6729\n",
      "372/372 - 42s - loss: 0.8343 - accuracy: 0.6373\n",
      "93/93 - 3s - loss: 0.7954 - accuracy: 0.6789\n",
      "372/372 - 40s - loss: 0.8341 - accuracy: 0.6420\n",
      "93/93 - 2s - loss: 0.7484 - accuracy: 0.6868\n",
      "372/372 - 41s - loss: 0.8306 - accuracy: 0.6432\n",
      "93/93 - 2s - loss: 0.8187 - accuracy: 0.6652\n",
      "Epoch 1/2\n",
      "372/372 - 37s - loss: 0.8281 - accuracy: 0.6439\n",
      "Epoch 2/2\n",
      "372/372 - 37s - loss: 0.6806 - accuracy: 0.7089\n",
      "93/93 - 2s - loss: 0.7269 - accuracy: 0.6864\n",
      "Epoch 1/2\n",
      "372/372 - 40s - loss: 0.8298 - accuracy: 0.6434\n",
      "Epoch 2/2\n",
      "372/372 - 42s - loss: 0.6783 - accuracy: 0.7132\n",
      "93/93 - 4s - loss: 0.7364 - accuracy: 0.6815\n",
      "Epoch 1/2\n",
      "372/372 - 38s - loss: 0.8312 - accuracy: 0.6419\n",
      "Epoch 2/2\n",
      "372/372 - 38s - loss: 0.6783 - accuracy: 0.7086\n",
      "93/93 - 2s - loss: 0.7477 - accuracy: 0.6810\n",
      "Epoch 1/2\n",
      "372/372 - 40s - loss: 0.8422 - accuracy: 0.6385\n",
      "Epoch 2/2\n",
      "372/372 - 40s - loss: 0.6861 - accuracy: 0.7077\n",
      "93/93 - 2s - loss: 0.7702 - accuracy: 0.6631\n",
      "Epoch 1/2\n",
      "372/372 - 45s - loss: 0.8223 - accuracy: 0.6457\n",
      "Epoch 2/2\n",
      "372/372 - 49s - loss: 0.6728 - accuracy: 0.7143\n",
      "93/93 - 3s - loss: 0.7742 - accuracy: 0.6625\n",
      "186/186 - 24s - loss: 0.8446 - accuracy: 0.6377\n",
      "47/47 - 2s - loss: 0.7676 - accuracy: 0.6450\n",
      "186/186 - 24s - loss: 0.8348 - accuracy: 0.6371\n",
      "47/47 - 2s - loss: 0.7920 - accuracy: 0.6520\n",
      "186/186 - 24s - loss: 0.8520 - accuracy: 0.6322\n",
      "47/47 - 1s - loss: 0.7656 - accuracy: 0.6826\n",
      "186/186 - 25s - loss: 0.8579 - accuracy: 0.6304\n",
      "47/47 - 2s - loss: 0.7554 - accuracy: 0.6738\n",
      "186/186 - 30s - loss: 0.8458 - accuracy: 0.6375\n",
      "47/47 - 2s - loss: 0.7877 - accuracy: 0.6717\n",
      "Epoch 1/2\n",
      "186/186 - 24s - loss: 0.8515 - accuracy: 0.6341\n",
      "Epoch 2/2\n",
      "186/186 - 26s - loss: 0.7054 - accuracy: 0.6975\n",
      "47/47 - 2s - loss: 0.7455 - accuracy: 0.6848\n",
      "Epoch 1/2\n",
      "186/186 - 46s - loss: 0.8440 - accuracy: 0.6324\n",
      "Epoch 2/2\n",
      "186/186 - 45s - loss: 0.6912 - accuracy: 0.7070\n",
      "47/47 - 3s - loss: 0.7368 - accuracy: 0.6837\n",
      "Epoch 1/2\n",
      "186/186 - 64s - loss: 0.8521 - accuracy: 0.6302\n",
      "Epoch 2/2\n",
      "186/186 - 62s - loss: 0.7041 - accuracy: 0.6987\n",
      "47/47 - 5s - loss: 0.7504 - accuracy: 0.6756\n",
      "Epoch 1/2\n",
      "186/186 - 60s - loss: 0.8535 - accuracy: 0.6328\n",
      "Epoch 2/2\n",
      "186/186 - 56s - loss: 0.6929 - accuracy: 0.7033\n",
      "47/47 - 4s - loss: 0.7485 - accuracy: 0.6819\n",
      "Epoch 1/2\n",
      "186/186 - 47s - loss: 0.8452 - accuracy: 0.6383\n",
      "Epoch 2/2\n",
      "186/186 - 31s - loss: 0.6820 - accuracy: 0.7093\n",
      "47/47 - 2s - loss: 0.7714 - accuracy: 0.6765\n",
      "Epoch 1/2\n",
      "930/930 - 137s - loss: 0.8136 - accuracy: 0.6525\n",
      "Epoch 2/2\n",
      "930/930 - 139s - loss: 0.6754 - accuracy: 0.7137\n",
      "Best: 0.680726 using {'batch_size': 10, 'epochs': 2}\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn=createmodel,verbose=2)\n",
    "batch_size= [10, 20, 40]\n",
    "epochs = [1, 2]\n",
    "param_grid= {'batch_size':batch_size, 'epochs':epochs}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid  = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result= grid.fit(X_train,Y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
